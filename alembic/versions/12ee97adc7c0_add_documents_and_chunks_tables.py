"""add documents and chunks tables

Revision ID: 12ee97adc7c0
Revises: b37cd2b68a75
Create Date: 2025-08-14 10:43:18.473256

"""

from collections.abc import Sequence

import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

from alembic import op

# revision identifiers, used by Alembic.
revision: str = "12ee97adc7c0"
down_revision: str | Sequence[str] | None = "b37cd2b68a75"
branch_labels: str | Sequence[str] | None = None
depends_on: str | Sequence[str] | None = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table(
        "documents",
        sa.Column("id", sa.String(), nullable=False),
        sa.Column("filename", sa.String(length=255), nullable=False),
        sa.Column("original_filename", sa.String(length=255), nullable=True),
        sa.Column("content_hash", sa.String(length=64), nullable=False),
        sa.Column("file_size", sa.Integer(), nullable=False),
        sa.Column("mime_type", sa.String(length=100), nullable=False),
        sa.Column("page_count", sa.Integer(), nullable=True),
        sa.Column("word_count", sa.Integer(), nullable=True),
        sa.Column("language", sa.String(length=10), nullable=True),
        sa.Column("uploaded_at", sa.DateTime(), nullable=True),
        sa.Column("updated_at", sa.DateTime(), nullable=True),
        sa.Column("processed_at", sa.DateTime(), nullable=True),
        sa.Column("author", sa.String(length=100), nullable=True),
        sa.Column("tags", postgresql.ARRAY(sa.String()), nullable=True),
        sa.Column(
            "status",
            sa.Enum(
                "PENDING", "PROCESSING", "COMPLETED", "FAILED", "PAUSED", name="document_status"
            ),
            nullable=True,
        ),
        sa.Column("version", sa.Integer(), nullable=True),
        sa.Column("storage_backend", sa.String(length=20), nullable=True),
        sa.Column("storage_uri", sa.Text(), nullable=False),
        sa.Column("soft_deleted", sa.Boolean(), nullable=True),
        sa.Column("created_by", sa.String(length=100), nullable=True),
        sa.Column("extra_metadata", sa.JSON(), nullable=True),
        sa.CheckConstraint("file_size > 0 AND file_size <= 104857600", name="valid_file_size"),
        sa.CheckConstraint("version > 0", name="valid_version"),
        sa.PrimaryKeyConstraint("id"),
        sa.UniqueConstraint("content_hash"),
    )
    op.create_index("idx_documents_content_hash", "documents", ["content_hash"], unique=False)
    op.create_index(
        "idx_documents_status",
        "documents",
        ["status"],
        unique=False,
        postgresql_where=sa.text("NOT soft_deleted"),
    )
    op.create_index(
        "idx_documents_tags", "documents", ["tags"], unique=False, postgresql_using="gin"
    )
    op.create_index("idx_documents_uploaded_at", "documents", ["uploaded_at"], unique=False)
    op.create_table(
        "processing_jobs",
        sa.Column("id", sa.String(), nullable=False),
        sa.Column("job_type", sa.String(length=50), nullable=False),
        sa.Column("status", sa.String(length=20), nullable=True),
        sa.Column("input_data", sa.JSON(), nullable=False),
        sa.Column("result_data", sa.JSON(), nullable=True),
        sa.Column("error_message", sa.Text(), nullable=True),
        sa.Column("progress_percent", sa.Integer(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=True),
        sa.Column("started_at", sa.DateTime(), nullable=True),
        sa.Column("completed_at", sa.DateTime(), nullable=True),
        sa.Column("created_by", sa.String(length=100), nullable=True),
        sa.CheckConstraint(
            "progress_percent >= 0 AND progress_percent <= 100", name="valid_progress"
        ),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index(
        "idx_processing_jobs_status", "processing_jobs", ["status", "created_at"], unique=False
    )
    op.create_table(
        "document_chunks",
        sa.Column("id", sa.String(), nullable=False),
        sa.Column("document_id", sa.String(), nullable=True),
        sa.Column("chunk_index", sa.Integer(), nullable=False),
        sa.Column("content", sa.Text(), nullable=False),
        sa.Column("content_hash", sa.String(length=64), nullable=False),
        sa.Column("token_count", sa.Integer(), nullable=True),
        sa.Column("chunk_type", sa.String(length=50), nullable=True),
        sa.Column("page_number", sa.Integer(), nullable=True),
        sa.Column("section_title", sa.String(length=255), nullable=True),
        sa.Column("extra_metadata", sa.JSON(), nullable=True),
        sa.Column("created_at", sa.DateTime(), nullable=True),
        sa.CheckConstraint("chunk_index >= 0", name="valid_chunk_index"),
        sa.CheckConstraint("token_count IS NULL OR token_count > 0", name="valid_token_count"),
        sa.ForeignKeyConstraint(["document_id"], ["documents.id"], ondelete="CASCADE"),
        sa.PrimaryKeyConstraint("id"),
    )
    op.create_index("idx_chunks_content_hash", "document_chunks", ["content_hash"], unique=False)
    op.create_index("idx_chunks_document_id", "document_chunks", ["document_id"], unique=False)
    op.create_index(
        "uq_document_chunk_idx", "document_chunks", ["document_id", "chunk_index"], unique=True
    )
    op.drop_index(
        op.f("content_embeddings_vector_hnsw_idx"),
        table_name="content_embeddings",
        postgresql_with={"m": "32", "ef_construction": "64"},
        postgresql_using="hnsw",
    )
    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_index(
        op.f("content_embeddings_vector_hnsw_idx"),
        "content_embeddings",
        ["content_vector"],
        unique=False,
        postgresql_with={"m": "32", "ef_construction": "64"},
        postgresql_using="hnsw",
    )
    op.drop_index("uq_document_chunk_idx", table_name="document_chunks")
    op.drop_index("idx_chunks_document_id", table_name="document_chunks")
    op.drop_index("idx_chunks_content_hash", table_name="document_chunks")
    op.drop_table("document_chunks")
    op.drop_index("idx_processing_jobs_status", table_name="processing_jobs")
    op.drop_table("processing_jobs")
    op.drop_index("idx_documents_uploaded_at", table_name="documents")
    op.drop_index("idx_documents_tags", table_name="documents", postgresql_using="gin")
    op.drop_index(
        "idx_documents_status", table_name="documents", postgresql_where=sa.text("NOT soft_deleted")
    )
    op.drop_index("idx_documents_content_hash", table_name="documents")
    op.drop_table("documents")
    # ### end Alembic commands ###
