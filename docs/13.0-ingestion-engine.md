# Ingestion Engine

This document describes the ingestion pipeline, endpoints, and related components.

## Endpoints

- POST `/api/v1/docs/upload`: Upload a document (multipart/form-data)
- GET `/api/v1/docs`: List documents
- GET `/api/v1/docs/{id}`: Get document metadata
- GET `/api/v1/docs/status/{id}`: Get ingestion status
- POST `/api/v1/docs/detect-changes`: Detect changed pages
- PUT `/api/v1/docs/apply-changes`: Apply detected changes
- GET `/api/v1/docs/jobs/{job_id}`: Get background job status

## Components

- `FormatProcessor`: converts file input into raw text (`supports()`, `process()`)
- `AdaptiveChunker`: splits text into chunks (`chunk()`)
- `IngestionEngine`: orchestrates, validates, and emits progress events (`started`, `processed`, `chunked`, `completed`, `failed`)
- `IncrementalProcessor`: detects changes and re-embeds only changed pages

## Diagrams

- `docs/diagrams/data_flow.mmd` — shows upload, storage backend (Local/MinIO), retrieval and metrics
- `docs/diagrams/database_schema.mmd` — shows `documents` and `document_chunks` tables with metadata

## Notes

- Files are stored via the configured storage backend (`STORAGE_BACKEND=local|minio`)
- Duplicate uploads reuse storage URI via content-hash keyed cache
- Background processing is executed via Celery workers with correlation IDs
