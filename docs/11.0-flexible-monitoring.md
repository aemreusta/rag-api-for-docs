# Flexible Monitoring Architecture

This document describes the flexible monitoring architecture implemented in the chatbot API service, which supports multiple observability backends through a pluggable design.

## Overview

The monitoring system provides a vendor-agnostic approach to metrics collection, allowing seamless switching between different monitoring tools without code changes. This enables:

- Easy migration between monitoring providers
- Environment-specific backends (development vs production)
- Zero vendor lock-in with standardized metrics interface
- Auto-detection of available monitoring libraries

![Monitoring Architecture](diagrams/monitoring_architecture.mmd)

## Supported Backends

### 1. Prometheus Backend ✅

For Kubernetes/Docker deployments:

```bash
METRICS_BACKEND=prometheus
PROMETHEUS_ENABLED=true
```

Features:

- Self-hosted environments, Kubernetes clusters
- Metrics endpoint: `http://localhost:8000/metrics`
- Format: Prometheus exposition format
- Integration: Works with Grafana, Alertmanager

### 2. DataDog Backend ✅  

For enterprise SaaS environments:

```bash
METRICS_BACKEND=datadog
DATADOG_API_KEY=your-api-key-here
```

Features:

- Enterprise SaaS environments
- Authentication: API key required
- Features: Tagged metrics, custom events, APM traces
- Integration: DataDog dashboard, alerting, logs correlation

### 3. OpenTelemetry Backend ✅

For cloud-native observability:

```bash
METRICS_BACKEND=opentelemetry
```

Features:

- Cloud-native applications, multi-cloud
- Advantages: Vendor-neutral, future-proof
- Export targets: Jaeger, Tempo, cloud providers
- Integration: Traces, metrics, and logs correlation

### 4. NoOp Backend ✅

For development and testing:

```bash
METRICS_BACKEND=noop
```

Features:

- Local development, unit testing
- Performance: Zero overhead, no network calls
- Behavior: Silent operation, metrics discarded

### 5. Auto-Detection (Default) ✅

For automatic backend selection:

```bash
METRICS_BACKEND=auto  # Default value
```

Features:

- Detects installed libraries and configuration
- Priority: Prometheus → DataDog → OpenTelemetry → NoOp
- Fallback: Always succeeds with NoOp if nothing else available

## Available Metrics

### Vector Search Performance

| Metric Name | Type | Description | Labels |
|-------------|------|-------------|---------|
| `vector_search_duration_seconds` | Histogram | Vector similarity search latency | `status`, `model` |
| `vector_search_requests_total` | Counter | Total vector search requests | `status`, `model` |
| `vector_search_recall` | Gauge | Search recall accuracy (0.0-1.0) | `k` (top-k results) |

### Ingestion Metrics

| Metric Name | Type | Description | Labels |
|-------------|------|-------------|---------|
| `ingest_requests_total` | Counter | Total document ingest requests | `status` |
| `ingest_latency_seconds` | Histogram | Validation/enqueue latency for ingest | `status` |
| `ingest_job_duration_seconds` | Histogram | Background ingest job duration | `job_type`, `status` |
| `ingest_jobs_total` | Counter | Ingestion job outcomes | `job_type`, `status` |
| `ingest_pages_processed_total` | Counter | Pages processed during incremental updates | `status` |
| `ingest_chunks_processed_total` | Counter | Chunks processed during incremental updates | `status` |

**Example Values:**

- `vector_search_duration_seconds{status="success",model="sentence-transformers"}`: P99 = 0.00188s
- `vector_search_recall{k="10"}`: 1.0 (100% recall)

### HTTP Request Metrics

| Metric Name | Type | Description | Labels |
|-------------|------|-------------|---------|
| `http_requests_total` | Counter | Total HTTP requests | `method`, `endpoint`, `status_code` |
| `http_request_duration_seconds` | Histogram | HTTP request duration | `method`, `endpoint` |

### LLM Provider Metrics

| Metric Name | Type | Description | Labels |
|-------------|------|-------------|---------|
| `llm_provider_requests_total` | Counter | Total LLM provider requests | `provider`, `model`, `status` |
| `llm_provider_errors_total` | Counter | LLM provider error count | `provider`, `error_type` |
| `llm_fallback_triggered_total` | Counter | Provider fallback events | `from_provider`, `to_provider` |

## Configuration

### Environment Variables

```bash
# Backend Selection
METRICS_BACKEND=auto|prometheus|datadog|opentelemetry|noop

# Prometheus Configuration
PROMETHEUS_ENABLED=true
PROMETHEUS_MULTIPROC_DIR=/tmp/prometheus_multiproc

# DataDog Configuration  
DATADOG_API_KEY=your-datadog-api-key
DATADOG_SITE=datadoghq.com  # or datadoghq.eu

# OpenTelemetry Configuration
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4317
OTEL_SERVICE_NAME=chatbot-api-service
```

### Settings in `app/core/config.py`

```python
class Settings(BaseSettings):
    # Flexible Monitoring Configuration
    METRICS_BACKEND: str = "auto"
    PROMETHEUS_ENABLED: bool = True
    DATADOG_API_KEY: str | None = None
    OTEL_EXPORTER_OTLP_ENDPOINT: str = "http://localhost:4317"
```

## Usage

### Basic Metrics Collection

```python
from app.core.monitoring import get_metrics_backend

# Get configured backend (auto-detected or specified)
metrics = get_metrics_backend()

# Record vector search timing
with metrics.record_duration("vector_search_duration_seconds", {"model": "sentence-transformers"}):
    results = vector_store.similarity_search(query, k=10)

# Increment counters
metrics.increment_counter("vector_search_requests_total", {"status": "success", "model": "sentence-transformers"})

# Set gauge values
recall_score = calculate_recall(results, ground_truth)
metrics.set_gauge("vector_search_recall", recall_score, {"k": "10"})
```

### Integration with Vector Search

```python
# In app/core/query_engine.py
from app.core.monitoring import get_metrics_backend

class OptimizedQueryEngine:
    def __init__(self):
        self.metrics = get_metrics_backend()
    
    async def similarity_search(self, query: str, k: int = 10):
        start_time = time.time()
        
        try:
            results = await self._perform_search(query, k)
            
            # Record successful search
            duration = time.time() - start_time
            self.metrics.record_duration(
                "vector_search_duration_seconds", 
                duration,
                {"status": "success", "model": "sentence-transformers"}
            )
            self.metrics.increment_counter(
                "vector_search_requests_total",
                {"status": "success", "model": "sentence-transformers"}
            )
            
            return results
            
        except Exception as e:
            # Record failed search
            self.metrics.increment_counter(
                "vector_search_requests_total",
                {"status": "error", "model": "sentence-transformers"}
            )
            raise
```

## Migration Between Backends

### Development → Production

```bash
# Development (no metrics overhead)
METRICS_BACKEND=noop

# Production (Prometheus + Grafana)  
METRICS_BACKEND=prometheus
PROMETHEUS_ENABLED=true
```

### Self-hosted → SaaS

```bash
# Self-hosted Prometheus
METRICS_BACKEND=prometheus

# Migrate to DataDog SaaS
METRICS_BACKEND=datadog
DATADOG_API_KEY=your-api-key
```

### Vendor-neutral Migration

```bash
# Any existing backend
METRICS_BACKEND=prometheus|datadog

# Switch to vendor-neutral OpenTelemetry
METRICS_BACKEND=opentelemetry
OTEL_EXPORTER_OTLP_ENDPOINT=http://your-collector:4317
```

**Zero Code Changes Required** - just update environment variables!

## Backend Implementation

### MetricsBackend Interface

```python
from abc import ABC, abstractmethod
from typing import Dict, Any

class MetricsBackend(ABC):
    @abstractmethod
    def increment_counter(self, name: str, labels: Dict[str, str] = None) -> None:
        """Increment a counter metric."""
        pass
    
    @abstractmethod
    def record_duration(self, name: str, duration: float, labels: Dict[str, str] = None) -> None:
        """Record a duration measurement."""
        pass
    
    @abstractmethod
    def set_gauge(self, name: str, value: float, labels: Dict[str, str] = None) -> None:
        """Set a gauge metric value."""
        pass
    
    @abstractmethod
    def record_histogram(self, name: str, value: float, labels: Dict[str, str] = None) -> None:
        """Record a histogram measurement."""
        pass
```

### Auto-Detection Logic

```python
def create_metrics_backend(backend_type: str = "auto") -> MetricsBackend:
    if backend_type == "auto":
        # Auto-detect available backend
        if _has_datadog_config():
            return DataDogBackend()
        elif _has_prometheus_client():
            return PrometheusBackend()
        elif _has_opentelemetry():
            return OpenTelemetryBackend()
        else:
            return NoOpBackend()
    
    elif backend_type == "prometheus":
        return PrometheusBackend()
    elif backend_type == "datadog":
        return DataDogBackend()
    elif backend_type == "opentelemetry":
        return OpenTelemetryBackend()
    elif backend_type == "noop":
        return NoOpBackend()
    else:
        raise ValueError(f"Unknown metrics backend: {backend_type}")
```

## Performance Impact

### Benchmark Results

| Backend | Overhead per Metric | Memory Usage | Network Calls |
|---------|-------------------|--------------|---------------|
| NoOp | ~0.1μs | 0 MB | None |
| Prometheus | ~2.5μs | ~1 MB | None (pull-based) |
| DataDog | ~15μs | ~2 MB | Batched HTTP |
| OpenTelemetry | ~8μs | ~1.5 MB | gRPC/HTTP |

### Production Recommendations

#### High-throughput APIs

Use `noop` in development, `prometheus` in production

#### Enterprise Environments

DataDog for comprehensive APM and alerting

#### Multi-cloud Setups

OpenTelemetry for vendor portability

#### Cost-sensitive Deployments

Prometheus (self-hosted, no per-metric pricing)

## Monitoring Dashboard Examples

### Grafana (Prometheus)

```promql
# Vector search P99 latency
histogram_quantile(0.99, vector_search_duration_seconds_bucket)

# Vector search success rate
rate(vector_search_requests_total{status="success"}[5m]) / 
rate(vector_search_requests_total[5m])

# LLM provider fallback rate
rate(llm_fallback_triggered_total[5m])
```

### DataDog Queries

```
# Average vector search latency
avg:vector_search_duration_seconds{*}

# Vector search error rate  
rate(vector_search_requests_total{status:error})

# Top LLM provider errors
top(llm_provider_errors_total{*} by {provider,error_type}, 10, 'mean', 'desc')
```

## Troubleshooting

### Common Issues

#### Backend Auto-Detection Fails

If auto-detection is not working as expected:

```bash
# Check available libraries
python -c "import prometheus_client; print('Prometheus available')" 2>/dev/null
python -c "import datadog; print('DataDog available')" 2>/dev/null

# Force specific backend
METRICS_BACKEND=noop  # Always works
```

#### DataDog Authentication Errors

If you're having issues with DataDog authentication:

```bash
# Verify API key
curl -X GET "https://api.datadoghq.com/api/v1/validate" \
     -H "DD-API-KEY: ${DATADOG_API_KEY}"

# Check network connectivity
METRICS_BACKEND=datadog python -c "
from app.core.monitoring import get_metrics_backend
metrics = get_metrics_backend()
metrics.increment_counter('test_metric')
"
```

#### Prometheus Metrics Not Appearing

If Prometheus metrics are not appearing:

```bash
# Check metrics endpoint
curl http://localhost:8000/metrics | grep vector_search

# Verify multiprocess setup
ls -la $PROMETHEUS_MULTIPROC_DIR
```

### Migration Checklist

- Update `METRICS_BACKEND` environment variable
- Add backend-specific configuration (API keys, endpoints)  
- Restart application containers
- Verify metrics appear in new backend
- Update dashboards and alerts
- Test failover scenarios

## Security Considerations

### API Key Management

```bash
# DataDog API key security
echo "DATADOG_API_KEY=dd-api-key-here" >> .env
chmod 600 .env

# Use secrets management in production
kubectl create secret generic datadog-secret \
  --from-literal=api-key="your-api-key"
```

### Network Security

#### Internal Scraping

Prometheus: No outbound calls required

#### External Services

- DataDog: HTTPS to api.datadoghq.com (outbound required)
- OpenTelemetry: Configurable endpoints (internal/external)
- NoOp: No network calls

### Data Privacy

All backends automatically exclude sensitive data from metrics:

- API keys and passwords are never logged
- User-specific identifiers are hashed or excluded
- Only aggregate performance data is collected

## Future Extensions

### Adding New Backends

```python
class NewRelicBackend(MetricsBackend):
    def __init__(self):
        import newrelic.agent
        self.agent = newrelic.agent
    
    def increment_counter(self, name: str, labels: Dict[str, str] = None) -> None:
        self.agent.record_custom_metric(f"Custom/{name}", 1)
    
    # ... implement other methods
```

### Custom Metrics

```python
# Add application-specific metrics
metrics.increment_counter("chat_conversations_started", {"language": "turkish"})
metrics.record_duration("pdf_processing_time", duration, {"pages": str(page_count)})
metrics.set_gauge("active_sessions", session_count)
```

This flexible architecture ensures your monitoring strategy can evolve with your infrastructure needs without requiring code changes.
