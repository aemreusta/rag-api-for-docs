# Tech Stack

Embeddings:

- Google Gemini `gemini-embedding-001` (MRL dims: 3072/1536/768; default 1536)

This project is a pragmatic FastAPI-based RAG service with a small operational footprint and clear observability.

| Component | Choice | Why |
|---|---|---|
| API | FastAPI | Fast, typed, great docs |
| Retrieval | PostgreSQL + pgvector (HNSW) | Proven, easy ops, low latency |
| LLM orchestration | LlamaIndex + simple router | Clean ingestion/query, pluggable providers |
| Cache & limits | Redis | Rate limiting + cross-worker cache |
| Observability | Langfuse (optional) | Traces/evals; pairs well with logs |
| Metrics | Prometheus/DataDog/OpenTelemetry/NoOp | Pick via env; zero code changes |
| Language | Python 3.10+ | Modern async + typing |
| Containers | Docker Compose | One-command local stack |

Notes:

- HNSW index is enabled for fast vector search.
- Switch metrics backends with `METRICS_BACKEND` (auto/prometheus/datadog/opentelemetry/noop).
- Use your preferred LLM provider (OpenRouter, Groq, OpenAI). Set only the keys you need.
